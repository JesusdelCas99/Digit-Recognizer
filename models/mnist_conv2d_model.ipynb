{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "278b7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4c02fd9-1f8b-4eb4-ad63-c6b52a5b071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available...\n",
      "GPU Device Name: NVIDIA GeForce RTX 2070\n",
      "CUDA Version: 12.4\n",
      "Number of GPUs: 1\n",
      "GPU Device 0 Name: NVIDIA GeForce RTX 2070\n",
      "Current GPU Device: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available...\")\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU Device {i} Name: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "    print(\"Current GPU Device:\", torch.cuda.current_device())\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "gpu_index = 0  # Change this to the index of the GPU you want to use\n",
    "device = torch.device(f\"cuda:{gpu_index}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "154059df-9989-4306-8c8d-60cfb74935ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ab439-14fc-484d-ba82-6f42fde751af",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "145421ba-429d-445f-bea4-73f173b6054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class\n",
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1, 64 * 28 * 28)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cadd195-4191-4542-b21c-54770a674bb1",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "359dc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_data = np.genfromtxt('../data/train.csv', delimiter=',', skip_header=1)\n",
    "test_data = np.genfromtxt('../data/test.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Reshape training and test images to 28x28 pixels\n",
    "train_images = train_data[:, 1:].reshape(train_data.shape[0], 28, 28)\n",
    "test_images = test_data.reshape(test_data.shape[0], 28, 28)\n",
    "\n",
    "# Extract train labels from data\n",
    "train_labels = train_data[:, 0]\n",
    "\n",
    "# Ensure data is in the form of PyTorch tensors\n",
    "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
    "test_images = torch.tensor(test_images, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8f390-500c-426a-983a-9d0ba41a610c",
   "metadata": {},
   "source": [
    "### Train the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "883b95ff-22fb-46a5-85f5-213150a596d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/250], Mean batch loss: 0.5594\n",
      "Validation - Mean batch loss: 0.1457, Accuracy: 95.58%\n",
      "Training - Epoch [2/250], Mean batch loss: 0.0561\n",
      "Validation - Mean batch loss: 0.1039, Accuracy: 97.18%\n",
      "Training - Epoch [3/250], Mean batch loss: 0.0292\n",
      "Validation - Mean batch loss: 0.1438, Accuracy: 96.75%\n",
      "Training - Epoch [4/250], Mean batch loss: 0.0218\n",
      "Validation - Mean batch loss: 0.1362, Accuracy: 97.45%\n",
      "Training - Epoch [5/250], Mean batch loss: 0.0233\n",
      "Validation - Mean batch loss: 0.1945, Accuracy: 96.53%\n",
      "Training - Epoch [6/250], Mean batch loss: 0.0239\n",
      "Validation - Mean batch loss: 0.1221, Accuracy: 97.51%\n",
      "Training - Epoch [7/250], Mean batch loss: 0.0104\n",
      "Validation - Mean batch loss: 0.1436, Accuracy: 97.41%\n",
      "Training - Epoch [8/250], Mean batch loss: 0.0136\n",
      "Validation - Mean batch loss: 0.1537, Accuracy: 97.39%\n",
      "Training - Epoch [9/250], Mean batch loss: 0.0198\n",
      "Validation - Mean batch loss: 0.1267, Accuracy: 97.73%\n",
      "Training - Epoch [10/250], Mean batch loss: 0.0122\n",
      "Validation - Mean batch loss: 0.1718, Accuracy: 97.61%\n",
      "Training - Epoch [11/250], Mean batch loss: 0.0191\n",
      "Validation - Mean batch loss: 0.1687, Accuracy: 97.64%\n",
      "Training - Epoch [12/250], Mean batch loss: 0.0149\n",
      "Validation - Mean batch loss: 0.1723, Accuracy: 97.78%\n",
      "Training - Epoch [13/250], Mean batch loss: 0.0070\n",
      "Validation - Mean batch loss: 0.1971, Accuracy: 97.47%\n",
      "Training - Epoch [14/250], Mean batch loss: 0.0151\n",
      "Validation - Mean batch loss: 0.2169, Accuracy: 97.54%\n",
      "Training - Epoch [15/250], Mean batch loss: 0.0140\n",
      "Validation - Mean batch loss: 0.1816, Accuracy: 98.04%\n",
      "Training - Epoch [16/250], Mean batch loss: 0.0115\n",
      "Validation - Mean batch loss: 0.2182, Accuracy: 97.86%\n",
      "Training - Epoch [17/250], Mean batch loss: 0.0084\n",
      "Validation - Mean batch loss: 0.2259, Accuracy: 97.61%\n",
      "Early stopping triggered after 17 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train dataset\n",
    "train_dataset = CustomDataset(train_images, train_labels)\n",
    "\n",
    "# Split the training dataset into training and validation sets (70%-30%)\n",
    "train_size = int(0.7 * train_images.shape[0])\n",
    "val_size = train_images.shape[0] - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MNISTCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MNISTCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 15  # Number of epochs to wait for improvement before stopping\n",
    "no_improvement_epochs = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 250\n",
    "\n",
    "# Loop through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Initialize running loss for the epoch\n",
    "    running_loss = 0.0\n",
    "    # Loop through each batch of images and labels in the training loader\n",
    "    for images, labels in train_loader:\n",
    "        # Prepare the images and labels for the model\n",
    "        images = images.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass: compute predicted outputs\n",
    "        outputs = model(images)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the mean batch loss for the epoch\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Mean batch loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0  # Initialize validation loss\n",
    "    correct = 0  # Initialize the number of correct predictions\n",
    "    total = 0  # Initialize the total number of predictions\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for images, labels in val_loader:\n",
    "            # Prepare the images and labels for the model\n",
    "            images = images.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(images)\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()  # Update the validation loss\n",
    "            # Get the predicted labels\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            # Update the total number of predictions and correct predictions\n",
    "            total += 64  # Batch size\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Print the mean batch loss and accuracy for the validation set\n",
    "    print(f'Validation - Mean batch loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17a8bf-56cb-46e2-9bef-ab4e9cd41e83",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test dataset and save the predictions to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c6d9696-9c8e-4f11-9a0a-67ec09879cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Loop through each test image\n",
    "for i in range(test_images.shape[0]):\n",
    "    # Prepare the image for the model\n",
    "    image = test_images[i].unsqueeze(0).unsqueeze(0).to(device)\n",
    "    # Get the model's output\n",
    "    output = model(image)\n",
    "    # Get the predicted label\n",
    "    _, predicted = torch.max(output.data, dim=1)\n",
    "    # Append the predicted label to the predictions list\n",
    "    predictions.append(predicted)\n",
    "\n",
    "# Write predictions to a CSV file\n",
    "with open('../submission/conv2d_submission.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header row in the CSV file\n",
    "    writer.writerow([\"ImageId\", \"Label\"])\n",
    "    # Write each prediction to the CSV file with the corresponding image ID\n",
    "    for i, label in enumerate(predictions, start=1):\n",
    "        writer.writerow([i, label.item()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
